{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color, img_as_bool, exposure, transform\n",
    "%matplotlib inline\n",
    "\n",
    "# location of original images\n",
    "subdirectory = 'images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read csv with pixel locations of aircraft and label updates\n",
    "new_labels_x = pd.read_csv('new_plane_labels.csv')\n",
    "print(new_labels_x.head())\n",
    "print(new_labels_x.dtypes)\n",
    "print(new_labels_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the labels being disregarded\n",
    "bad_labels = new_labels_x[new_labels_x['good_label']==False]\n",
    "print(bad_labels.shape)\n",
    "for index, row in bad_labels.iterrows():\n",
    "    toRead = subdirectory + row['img_name']\n",
    "    img_raw = io.imread(toRead)\n",
    "    plt.figure()\n",
    "    io.imshow(img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter to include only the *good* labels for training\n",
    "new_labels = new_labels_x[new_labels_x['good_label']==True]\n",
    "print(new_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = []\n",
    "y_list = []\n",
    "imnames_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get and look at examples of images containing aircraft\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "crop_pixels = 20 # number of pixels by which the crop will be furthered\n",
    "\n",
    "for index, row in new_labels.iterrows():\n",
    "    toRead = subdirectory + row['img_name']\n",
    "    img_raw = io.imread(toRead)\n",
    "    img_cropped = img_raw[row['y1_pixel'] + crop_pixels : row['y1_pixel'] + 90 - crop_pixels, \n",
    "                          row['x1_pixel'] + crop_pixels : row['x1_pixel'] + 160 - crop_pixels]\n",
    "    img_rs = transform.rescale(img_cropped, 0.8)\n",
    "    img_gray = color.rgb2gray(img_rs)\n",
    "    p1, p2 = np.percentile(img_gray, (3, 97))\n",
    "    img_rescale = exposure.rescale_intensity(img_gray, in_range=(p1, p2))\n",
    "    img_bool = img_as_bool(img_rescale)\n",
    "    final_image = img_bool\n",
    "    # save the final image to features_list\n",
    "    features_list.append(final_image)\n",
    "    imnames_list.append(row['img_name'])\n",
    "    y_list.append(True)\n",
    "    # view the image\n",
    "    plt.figure()\n",
    "    io.imshow(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read labels for aircraft images\n",
    "labels = pd.read_csv('aircraft.csv')\n",
    "print(labels.head())\n",
    "print(labels.shape)\n",
    "\n",
    "# create list of images that do not contain aircraft\n",
    "no_aircraft = labels[labels['aircraft']==False]['imageName']\n",
    "print(no_aircraft.shape)\n",
    "print(type(no_aircraft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features for non-aircraft\n",
    "from random import randrange, seed\n",
    "\n",
    "seed(5)\n",
    "i = 0\n",
    "\n",
    "for notplane in no_aircraft:\n",
    "    toRead = subdirectory + notplane\n",
    "    img_raw = io.imread(toRead)\n",
    "    # select a random area to begin the crop to 160x90\n",
    "    y1 = randrange(360-90)\n",
    "    x1 = randrange(640-160)\n",
    "    img_cropped = img_raw[y1 + crop_pixels : y1 + 90 - crop_pixels, x1 + crop_pixels : x1 + 160 - crop_pixels]\n",
    "    img_rs = transform.rescale(img_cropped, 0.8)\n",
    "    img_gray = color.rgb2gray(img_rs)\n",
    "    p2, p98 = np.percentile(img_gray, (3, 97))\n",
    "    img_rescale = exposure.rescale_intensity(img_gray, in_range=(p2, p98))\n",
    "    img_bool = img_as_bool(img_rescale)\n",
    "    features_list.append(img_bool)\n",
    "    imnames_list.append(notplane)\n",
    "    y_list.append(False)\n",
    "    i = i + 1\n",
    "    if i < 50:\n",
    "        plt.figure()\n",
    "        io.imshow(img_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BinaryClassificationPerformance():\n",
    "    '''Performance measures to evaluate the fit of a binary classification model'''\n",
    "    \n",
    "    def __init__(self, predictions, labels, desc, probabilities=None):\n",
    "        '''Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y'''\n",
    "        '''probabilities-optional, probability that Y is equal to True'''\n",
    "        self.probabilities = probabilities\n",
    "        self.performance_df = pd.concat([pd.DataFrame(predictions), pd.DataFrame(labels)], axis=1)\n",
    "        self.performance_df.columns = ['preds', 'labls']\n",
    "        self.desc = desc\n",
    "        self.performance_measures = {}\n",
    "        self.image_indices = {}\n",
    "  \n",
    "    def compute_measures(self):\n",
    "        '''Compute performance measures defined by Flach p. 57'''\n",
    "        self.performance_measures['Pos'] = self.performance_df['labls'].sum()\n",
    "        self.performance_measures['Neg'] = self.performance_df.shape[0] - self.performance_df['labls'].sum()\n",
    "        self.performance_measures['TP'] = ((self.performance_df['preds'] == True) & (self.performance_df['labls'] == True)).sum()\n",
    "        self.performance_measures['TN'] = ((self.performance_df['preds'] == False) & (self.performance_df['labls'] == False)).sum()\n",
    "        self.performance_measures['FP'] = ((self.performance_df['preds'] == True) & (self.performance_df['labls'] == False)).sum()\n",
    "        self.performance_measures['FN'] = ((self.performance_df['preds'] == False) & (self.performance_df['labls'] == True)).sum()\n",
    "        self.performance_measures['Accuracy'] = (self.performance_measures['TP'] + self.performance_measures['TN']) / (self.performance_measures['Pos'] + self.performance_measures['Neg'])\n",
    "        self.performance_measures['Precision'] = self.performance_measures['TP'] / (self.performance_measures['TP'] + self.performance_measures['FP'])\n",
    "        self.performance_measures['Recall'] = self.performance_measures['TP'] / self.performance_measures['Pos']\n",
    "\n",
    "    def img_indices(self):\n",
    "        '''Get the indices of true and false positives to be able to locate the corresponding images in a list of image names'''\n",
    "        self.performance_df['tp_ind'] = ((self.performance_df['preds'] == True) & (self.performance_df['labls'] == True))\n",
    "        self.performance_df['fp_ind'] = ((self.performance_df['preds'] == True) & (self.performance_df['labls'] == False))\n",
    "        self.image_indices['TP_indices'] = np.where(self.performance_df['tp_ind']==True)[0].tolist()\n",
    "        self.image_indices['FP_indices'] = np.where(self.performance_df['fp_ind']==True)[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### after the break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the lists to ndarrays\n",
    "features = np.asarray(features_list)\n",
    "Y = np.asarray(y_list)\n",
    "imgs = np.asarray(imnames_list)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# flatten the images ndarray to one row per image\n",
    "features_flat = features.reshape((features.shape[0], -1))\n",
    "print(features_flat.shape)\n",
    "print(Y.shape)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create train and test sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "data_train, data_test, y_train, y_test, imgs_train, imgs_test = train_test_split(features_flat, \n",
    "    Y, imgs, test_size = 0.5, random_state = 71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Perceptron\n",
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(data_train, y_train)\n",
    "\n",
    "prc_performance = BinaryClassificationPerformance(prc.predict(data_train), y_train, 'prc')\n",
    "prc_performance.compute_measures()\n",
    "print(prc_performance.performance_measures)\n",
    "\n",
    "prc_performance_test = BinaryClassificationPerformance(prc.predict(data_test), y_test, 'prc')\n",
    "prc_performance_test.compute_measures()\n",
    "print(prc_performance_test.performance_measures)\n",
    "\n",
    "prc_performance_test.img_indices()\n",
    "img_indices_to_view = prc_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at the true positives in the test set\n",
    "for i in range(len(img_indices_to_view['TP_indices'])):\n",
    "    toRead = subdirectory + imgs_test[img_indices_to_view['TP_indices'][i]]\n",
    "    img_raw = io.imread(toRead)\n",
    "    plt.figure()\n",
    "    io.imshow(img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the false positives in the test set\n",
    "for i in range(len(img_indices_to_view['FP_indices'])):\n",
    "    toRead = subdirectory + imgs_test[img_indices_to_view['FP_indices'][i]]\n",
    "    img_raw = io.imread(toRead)\n",
    "    plt.figure()\n",
    "    io.imshow(img_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MODEL: Multi-layer Perceptron aka neural network\n",
    "from sklearn import neural_network\n",
    "nn = neural_network.MLPClassifier()\n",
    "nn.fit(data_train, y_train)\n",
    "\n",
    "nn_performance = BinaryClassificationPerformance(nn.predict(data_train), y_train, 'nn')\n",
    "nn_performance.compute_measures()\n",
    "print(nn_performance.performance_measures)\n",
    "\n",
    "nn_performance_test = BinaryClassificationPerformance(nn.predict(data_test), y_test, 'nn_test')\n",
    "nn_performance_test.compute_measures()\n",
    "print(nn_performance_test.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
